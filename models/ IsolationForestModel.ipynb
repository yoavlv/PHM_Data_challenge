{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ac9324-bfc5-46d1-83a6-1610aa79f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efa9ba8-c83a-4cf2-a82d-e4a75cef6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_dataset():\n",
    "    all_data = []\n",
    "    scaler = MinMaxScaler()\n",
    "    columns = ['Input Voltage', 'Output Voltage', 'Tachometer']\n",
    "    num_rows = 122824\n",
    "    for i in range(1, 561): # 561\n",
    "        temp_df = pd.read_csv(f'../PHM09_competition_1/Run_{i}.csv', names=columns, nrows=num_rows)\n",
    "        normalized_data = scaler.fit_transform(temp_df)\n",
    "        temp_tensor = torch.tensor(normalized_data, dtype=torch.float32)\n",
    "        temp_tensor = temp_tensor.unsqueeze(dim=0) \n",
    "        all_data.append(temp_tensor)\n",
    "    \n",
    "    all_data_tensor = torch.stack(all_data, dim=0)\n",
    "    return all_data_tensor\n",
    "\n",
    "tensor_data = create_torch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d80fc8f-bfc1-4e27-a9c3-24f35a3d310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'max_samples': 0.25, 'contamination': 0.04, 'bootstrap': True, 'max_features': 1}\n",
      "Total Anomaly: 23\n",
      " Indices: [  8  78  88  96 126 162 179 183 207 269 288 345 396 403 441 468 472 482\n",
      " 483 532 537 553 554]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def scoring_function(predictions, expected_anomaly_rate):\n",
    "    \"\"\"\n",
    "    Custom scoring function for anomaly detection.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (numpy array): The array of predictions from the model, where -1 indicates an anomaly.\n",
    "    expected_anomaly_rate (float): The expected rate of anomalies in the data (between 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "    float: A score representing the performance of the model. Lower is better.\n",
    "    \"\"\"\n",
    "    # Calculate the rate of anomalies detected\n",
    "    anomaly_rate = np.mean(predictions == -1)\n",
    "\n",
    "    # Calculate the difference from the expected rate\n",
    "    score = abs(anomaly_rate - expected_anomaly_rate)\n",
    "\n",
    "    return score\n",
    "    \n",
    "flattened_data = tensor_data.view(tensor_data.shape[0], -1)\n",
    "\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params = {}\n",
    "predictions_best = None\n",
    "\n",
    "# Define a range of values for each parameter\n",
    "n_estimators_range = [50,100, 200]\n",
    "max_samples_range = [0.25, 0.5, 0.75, 1.0]\n",
    "contamination_range = [0.04] # The number of the anomalies 560*0.04 = 22.4\n",
    "bootstrap_range = [True, False]\n",
    "max_features_range = [1,2]\n",
    "\n",
    "# around 22 anomalies\n",
    "expected_anomaly_rate = 0.04\n",
    "\n",
    "# Iterate over all possible combinations of parameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_samples in max_samples_range:\n",
    "        for contamination in contamination_range:\n",
    "            for bootstrap in bootstrap_range:\n",
    "                for max_features in max_features_range:\n",
    "                    # Initialize the Isolation Forest with the current set of parameters\n",
    "                    iso_forest = IsolationForest(n_estimators=n_estimators, max_samples=max_samples, \n",
    "                                                contamination=contamination, bootstrap=bootstrap,\n",
    "                                                max_features=max_features)\n",
    "                    \n",
    "                    # Fit and predict\n",
    "                    iso_forest.fit(flattened_data)\n",
    "                    predictions = iso_forest.predict(flattened_data)\n",
    "\n",
    "                    # Evaluate your model here based on your specific criteria\n",
    "                    score = scoring_function(predictions, expected_anomaly_rate)\n",
    "\n",
    "                    # If this is the best score so far, save the parameters and predictions\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_params = {'n_estimators': n_estimators, 'max_samples': max_samples,\n",
    "                                       'contamination': contamination, 'bootstrap': bootstrap,\n",
    "                                       'max_features': max_features}\n",
    "                        predictions_best = predictions\n",
    "\n",
    "# Print out the best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Separating indices of anomalies and normal\n",
    "anomalies = np.where(predictions_best == -1)[0]\n",
    "normal = np.where(predictions_best == 1)[0]\n",
    "\n",
    "# Print anomalies and normal indices\n",
    "print(f\"Total Anomaly: {len(anomalies)}\\n Indices: {anomalies}\\n\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d6c263-a1ba-4926-864b-14fbcfe97d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'model': [str('IsolationForest')],  \n",
    "    'anomalies': [list(anomalies)],\n",
    "    'length': [len(anomalies)],\n",
    "    'params': [str(best_params)],\n",
    "    'hyper_params':None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a1a33dc-186a-40f6-957d-c551144204ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>length</th>\n",
       "      <th>params</th>\n",
       "      <th>hyper_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>[9, 53, 79, 84, 125, 149, 162, 172, 174, 179, ...</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_estimators': 50, 'max_samples': 0.25, 'con...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>[53, 82, 88, 111, 155, 162, 192, 195, 207, 269...</td>\n",
       "      <td>26</td>\n",
       "      <td>{'n_epochs': 100, 'loss_fn': 'L1Loss', 'params...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model                                          anomalies  length  \\\n",
       "0  IsolationForest  [9, 53, 79, 84, 125, 149, 162, 172, 174, 179, ...      23   \n",
       "1      Autoencoder  [53, 82, 88, 111, 155, 162, 192, 195, 207, 269...      26   \n",
       "\n",
       "                                              params hyper_params  \n",
       "0  {'n_estimators': 50, 'max_samples': 0.25, 'con...         None  \n",
       "1  {'n_epochs': 100, 'loss_fn': 'L1Loss', 'params...         None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def append_to_csv(data):\n",
    "    new_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        existing_data = pd.read_csv('anomaly_results.csv')\n",
    "        if data['model'][0] in existing_data['model'].values:\n",
    "            existing_data.loc[existing_data['model'] == data['model'][0]] = new_data.values\n",
    "        else:\n",
    "            existing_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        existing_data = new_data\n",
    "    existing_data.to_csv('anomaly_results.csv', index=False)\n",
    "    return existing_data\n",
    "\n",
    "df = append_to_csv(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
